"""
train_soccer.py - è¨“ç·´äººå½¢æ©Ÿå™¨äººè¸¢è¶³çƒ

ä½¿ç”¨ PPO æ¼”ç®—æ³•è¨“ç·´æ©Ÿå™¨äººï¼š
1. èµ°å‘è¶³çƒ
2. è¸¢çƒå‘çƒé–€

ä½¿ç”¨æ–¹å¼ï¼š
    python train_soccer.py
    
    # èª¿æ•´ä¸¦è¡Œç’°å¢ƒæ•¸é‡
    python train_soccer.py --n_envs 2
    
    # èª¿æ•´è¨“ç·´æ­¥æ•¸
    python train_soccer.py --timesteps 500000
"""

import os
import sys
import argparse
import torch
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize
from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback, BaseCallback
from stable_baselines3.common.monitor import Monitor

# å°å…¥è‡ªå®šç¾©ç’°å¢ƒ
from humanoid_soccer_env import HumanoidSoccerEnv


class ProgressCallback(BaseCallback):
    """è‡ªå®šç¾©é€²åº¦å›èª¿ï¼Œé¿å…å¡ä½å•é¡Œ"""
    def __init__(self, check_freq=1000, verbose=1):
        super().__init__(verbose)
        self.check_freq = check_freq
        
    def _on_step(self) -> bool:
        if self.n_calls % self.check_freq == 0:
            # å¼·åˆ¶åˆ·æ–°è¼¸å‡º
            print(f"Step: {self.num_timesteps}", flush=True)
            sys.stdout.flush()
        return True


def make_env():
    """å»ºç«‹å–®ä¸€ç’°å¢ƒ"""
    def _init():
        env = HumanoidSoccerEnv()
        env = Monitor(env)
        return env
    return _init


def train(n_envs=4, total_timesteps=1_000_000):
    """ä¸»è¨“ç·´å‡½æ•¸"""
    
    # ==================== è¨­å®š ====================
    SAVE_FREQ = 50_000
    
    # è³‡æ–™å¤¾è¨­å®š
    LOG_DIR = "./logs/soccer/"
    CHECKPOINT_DIR = "./checkpoints/soccer/"
    os.makedirs(LOG_DIR, exist_ok=True)
    os.makedirs(CHECKPOINT_DIR, exist_ok=True)
    
    # ç¢ºèª GPU
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è£ç½®: {device}")
    if device == "cuda":
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
    
    # ==================== å»ºç«‹ç’°å¢ƒ ====================
    
    print(f"\nğŸ“¦ å»ºç«‹ {n_envs} å€‹ç’°å¢ƒ (DummyVecEnv)...")
    
    # ä½¿ç”¨ DummyVecEnvï¼ˆWindows è¼ƒç©©å®šï¼‰
    env = DummyVecEnv([make_env() for _ in range(n_envs)])
    
    # æ­£è¦åŒ–è§€å¯Ÿå€¼å’Œçå‹µ
    env = VecNormalize(
        env,
        norm_obs=True,
        norm_reward=True,
        clip_obs=10.0,
        clip_reward=10.0,
    )
    
    print(f"   è§€å¯Ÿç©ºé–“: {env.observation_space.shape}")
    print(f"   å‹•ä½œç©ºé–“: {env.action_space.shape}")
    
    # ==================== å»ºç«‹æ¨¡å‹ ====================
    
    print("\nğŸ§  å»ºç«‹ PPO æ¨¡å‹...")
    
    model = PPO(
        "MlpPolicy",
        env,
        verbose=1,
        tensorboard_log=LOG_DIR,
        device=device,
        # PPO è¶…åƒæ•¸
        learning_rate=3e-4,
        n_steps=1024,        # æ¸›å°‘ä»¥åŠ å¿«æ›´æ–°
        batch_size=64,
        n_epochs=10,
        gamma=0.99,
        gae_lambda=0.95,
        clip_range=0.2,
        ent_coef=0.01,
        vf_coef=0.5,
        max_grad_norm=0.5,
        # ç¥ç¶“ç¶²è·¯è¨­å®š
        policy_kwargs={
            "net_arch": dict(pi=[256, 256], vf=[256, 256]),
        },
    )
    
    print(f"   æ¨¡å‹åƒæ•¸é‡: {sum(p.numel() for p in model.policy.parameters()):,}")
    
    # ==================== è¨­å®š Callbacks ====================
    
    # Checkpoint callback
    checkpoint_callback = CheckpointCallback(
        save_freq=max(SAVE_FREQ // n_envs, 1000),
        save_path=CHECKPOINT_DIR,
        name_prefix="soccer_humanoid",
        save_replay_buffer=False,
        save_vecnormalize=True,
    )
    
    # é€²åº¦å›èª¿
    progress_callback = ProgressCallback(check_freq=5000)
    
    # ==================== é–‹å§‹è¨“ç·´ ====================
    
    print(f"\nğŸš€ é–‹å§‹è¨“ç·´ {total_timesteps:,} æ­¥...")
    print(f"   TensorBoard: tensorboard --logdir={LOG_DIR}")
    print(f"   Checkpoints: {CHECKPOINT_DIR}")
    print("-" * 50)
    
    try:
        model.learn(
            total_timesteps=total_timesteps,
            callback=[checkpoint_callback, progress_callback],
            progress_bar=True,
        )
    except KeyboardInterrupt:
        print("\nâš ï¸  è¨“ç·´è¢«ä¸­æ–·ï¼Œæ­£åœ¨å„²å­˜æ¨¡å‹...")
    except Exception as e:
        print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        print("æ­£åœ¨å„²å­˜ç›®å‰çš„æ¨¡å‹...")
    
    # ==================== å„²å­˜æœ€çµ‚æ¨¡å‹ ====================
    
    print("\nğŸ’¾ å„²å­˜æœ€çµ‚æ¨¡å‹...")
    model.save(os.path.join(CHECKPOINT_DIR, "soccer_humanoid_final"))
    env.save(os.path.join(CHECKPOINT_DIR, "vec_normalize.pkl"))
    
    print("âœ… è¨“ç·´å®Œæˆï¼")
    print(f"   æ¨¡å‹ä½ç½®: {CHECKPOINT_DIR}")
    
    env.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è¨“ç·´è¶³çƒæ©Ÿå™¨äºº")
    parser.add_argument("--n_envs", type=int, default=2, help="ä¸¦è¡Œç’°å¢ƒæ•¸é‡ (é è¨­: 2)")
    parser.add_argument("--timesteps", type=int, default=1_000_000, help="è¨“ç·´æ­¥æ•¸ (é è¨­: 1000000)")
    args = parser.parse_args()
    
    train(n_envs=args.n_envs, total_timesteps=args.timesteps)