"""
HumanoidSoccerEnv - äººå½¢æ©Ÿå™¨äººè¶³çƒç’°å¢ƒ (ä¿®æ­£ç‰ˆ)

é€™å€‹ç’°å¢ƒè®“ humanoid æ©Ÿå™¨äººå­¸ç¿’èµ°å‘è¶³çƒä¸¦è¸¢å‘çƒé–€ã€‚
åŸºæ–¼ Gymnasium çš„ MujocoEnv å»ºç«‹ã€‚

ä½¿ç”¨æ–¹å¼ï¼š
    env = HumanoidSoccerEnv(render_mode="human")
    obs, info = env.reset()
    
    for _ in range(1000):
        action = env.action_space.sample()
        obs, reward, terminated, truncated, info = env.step(action)
"""

import numpy as np
import os
from gymnasium import utils
from gymnasium.envs.mujoco import MujocoEnv
from gymnasium.spaces import Box
import mujoco


class HumanoidSoccerEnv(MujocoEnv, utils.EzPickle):
    """
    äººå½¢æ©Ÿå™¨äººè¶³çƒç’°å¢ƒ
    """
    
    metadata = {
        "render_modes": ["human", "rgb_array", "depth_array"],
        "render_fps": 67,
    }
    
    def __init__(
        self,
        xml_file: str = None,
        frame_skip: int = 5,
        default_camera_config: dict = None,
        forward_reward_weight: float = 1.25,
        ctrl_cost_weight: float = 0.1,
        healthy_reward: float = 5.0,
        terminate_when_unhealthy: bool = True,
        healthy_z_range: tuple = (0.8, 2.1),
        reset_noise_scale: float = 1e-2,
        # è¶³çƒç›¸é—œåƒæ•¸
        ball_reward_weight: float = 2.0,
        kick_reward_weight: float = 5.0,
        goal_reward: float = 100.0,
        ball_initial_distance: float = 1.5,
        goal_position: tuple = (5.0, 0.0, 0.0),
        **kwargs,
    ):
        utils.EzPickle.__init__(
            self,
            xml_file,
            frame_skip,
            default_camera_config,
            forward_reward_weight,
            ctrl_cost_weight,
            healthy_reward,
            terminate_when_unhealthy,
            healthy_z_range,
            reset_noise_scale,
            ball_reward_weight,
            kick_reward_weight,
            goal_reward,
            ball_initial_distance,
            goal_position,
            **kwargs,
        )
        
        self._forward_reward_weight = forward_reward_weight
        self._ctrl_cost_weight = ctrl_cost_weight
        self._healthy_reward = healthy_reward
        self._terminate_when_unhealthy = terminate_when_unhealthy
        self._healthy_z_range = healthy_z_range
        self._reset_noise_scale = reset_noise_scale
        
        # è¶³çƒç›¸é—œ
        self._ball_reward_weight = ball_reward_weight
        self._kick_reward_weight = kick_reward_weight
        self._goal_reward = goal_reward
        self._ball_initial_distance = ball_initial_distance
        self._goal_position = np.array(goal_position)
        
        # å¦‚æœæ²’æŒ‡å®š xml_fileï¼Œä½¿ç”¨é è¨­è·¯å¾‘
        if xml_file is None:
            xml_file = os.path.join(os.path.dirname(__file__), "humanoid_soccer.xml")
        
        # é è¨­ç›¸æ©Ÿè¨­å®š
        if default_camera_config is None:
            default_camera_config = {
                "trackbodyid": 1,
                "distance": 5.0,
                "lookat": np.array([0.0, 0.0, 1.0]),
                "elevation": -20.0,
            }
        
        MujocoEnv.__init__(
            self,
            xml_file,
            frame_skip,
            observation_space=None,  # å…ˆè¨­ç‚º Noneï¼Œç¨å¾Œæœƒé‡æ–°è¨­å®š
            default_camera_config=default_camera_config,
            **kwargs,
        )
        
        # ========== é—œéµï¼šæ­£ç¢ºæ‰¾åˆ°çƒçš„ qpos/qvel ä½ç½® ==========
        self._ball_joint_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_JOINT, "ball_joint")
        self._ball_qpos_adr = self.model.jnt_qposadr[self._ball_joint_id]
        self._ball_qvel_adr = self.model.jnt_dofadr[self._ball_joint_id]
        
        # humanoid root joint
        self._root_joint_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_JOINT, "root")
        self._root_qpos_adr = self.model.jnt_qposadr[self._root_joint_id]
        
        # humanoid çš„ qpos æ•¸é‡ï¼ˆroot ä¹‹å¾Œåˆ° ball ä¹‹å‰ï¼‰
        self._humanoid_qpos_end = self._ball_qpos_adr
        self._humanoid_qvel_end = self._ball_qvel_adr
        
        print(f"[DEBUG] ball qpos èµ·å§‹: {self._ball_qpos_adr}, qvel èµ·å§‹: {self._ball_qvel_adr}")
        print(f"[DEBUG] humanoid qpos ç¯„åœ: 0-{self._humanoid_qpos_end}, qvel ç¯„åœ: 0-{self._humanoid_qvel_end}")
        print(f"[DEBUG] init_qpos[:7] (humanoid ä½ç½®+å§¿æ…‹): {self.init_qpos[:7]}")
        print(f"[DEBUG] init_qpos çƒä½ç½®: {self.init_qpos[self._ball_qpos_adr:self._ball_qpos_adr+3]}")
        
        # åˆå§‹åŒ–å¾Œï¼Œæ ¹æ“šå¯¦éš›è§€å¯Ÿé‡æ–°è¨­å®šè§€å¯Ÿç©ºé–“
        sample_obs = self._get_obs()
        self.observation_space = Box(
            low=-np.inf, high=np.inf, shape=sample_obs.shape, dtype=np.float64
        )
        
    @property
    def healthy_reward(self):
        return float(self.is_healthy or self._terminate_when_unhealthy) * self._healthy_reward
    
    def control_cost(self, action):
        return self._ctrl_cost_weight * np.sum(np.square(action))
    
    @property
    def is_healthy(self):
        min_z, max_z = self._healthy_z_range
        # humanoid çš„ z ä½ç½®åœ¨ qpos[2]
        is_healthy = min_z < self.data.qpos[2] < max_z
        return is_healthy
    
    @property
    def terminated(self):
        terminated = (not self.is_healthy) if self._terminate_when_unhealthy else False
        return terminated
    
    def _get_ball_position(self):
        """ç²å–çƒçš„ä½ç½®"""
        return self.data.qpos[self._ball_qpos_adr:self._ball_qpos_adr + 3].copy()
    
    def _get_ball_velocity(self):
        """ç²å–çƒçš„é€Ÿåº¦"""
        return self.data.qvel[self._ball_qvel_adr:self._ball_qvel_adr + 3].copy()
    
    def _get_robot_position(self):
        """ç²å–æ©Ÿå™¨äººï¼ˆè»€å¹¹ï¼‰çš„ä½ç½®"""
        return self.data.qpos[:3].copy()
    
    def _get_obs(self):
        """çµ„åˆè§€å¯Ÿç©ºé–“"""
        # humanoid çš„ qpos å’Œ qvelï¼ˆä¸åŒ…å«çƒï¼‰
        position = self.data.qpos[:self._humanoid_qpos_end].flat.copy()
        velocity = self.data.qvel[:self._humanoid_qvel_end].flat.copy()
        
        # çƒçš„è³‡è¨Š
        ball_pos = self._get_ball_position()
        ball_vel = self._get_ball_velocity()
        robot_pos = self._get_robot_position()
        
        # è¨ˆç®—ç›¸å°å‘é‡
        ball_to_goal = self._goal_position - ball_pos
        robot_to_ball = ball_pos - robot_pos
        
        # ç°¡åŒ–çš„è§€å¯Ÿç©ºé–“ï¼ˆä¸åŒ…å« cinert, cvel ç­‰è¤‡é›œè³‡è¨Šï¼‰
        return np.concatenate([
            position,
            velocity,
            ball_pos,
            ball_vel,
            ball_to_goal,
            robot_to_ball,
        ])
    
    def step(self, action):
        # è¨˜éŒ„å‹•ä½œå‰çš„ç‹€æ…‹
        robot_pos_before = self._get_robot_position()
        ball_pos_before = self._get_ball_position()
        
        # åŸ·è¡Œå‹•ä½œ
        self.do_simulation(action, self.frame_skip)
        
        # ç²å–å‹•ä½œå¾Œçš„ç‹€æ…‹
        robot_pos_after = self._get_robot_position()
        ball_pos_after = self._get_ball_position()
        
        # ==================== è¨ˆç®—çå‹µ ====================
        
        # 1. å­˜æ´»çå‹µ
        healthy_reward = self.healthy_reward
        
        # 2. æ§åˆ¶æˆæœ¬
        ctrl_cost = self.control_cost(action)
        
        # 3. æ¥è¿‘çƒçš„çå‹µ
        dist_to_ball_before = np.linalg.norm(robot_pos_before[:2] - ball_pos_before[:2])
        dist_to_ball_after = np.linalg.norm(robot_pos_after[:2] - ball_pos_after[:2])
        approach_ball_reward = self._ball_reward_weight * (dist_to_ball_before - dist_to_ball_after)
        
        # 4. è¸¢çƒå‘çƒé–€çš„çå‹µ
        ball_to_goal_before = np.linalg.norm(self._goal_position[:2] - ball_pos_before[:2])
        ball_to_goal_after = np.linalg.norm(self._goal_position[:2] - ball_pos_after[:2])
        kick_reward = self._kick_reward_weight * (ball_to_goal_before - ball_to_goal_after)
        
        # 5. é€²çƒçå‹µ
        goal_reward = 0.0
        if ball_pos_after[0] > 4.9 and abs(ball_pos_after[1]) < 1.0 and ball_pos_after[2] < 1.0:
            goal_reward = self._goal_reward
        
        # ç¸½çå‹µ
        reward = (
            healthy_reward
            - ctrl_cost
            + approach_ball_reward
            + kick_reward
            + goal_reward
        )
        
        # ==================== çµ‚æ­¢æ¢ä»¶ ====================
        terminated = self.terminated
        
        if goal_reward > 0:
            terminated = True
        
        observation = self._get_obs()
        
        info = {
            "reward_survive": healthy_reward,
            "reward_ctrl": -ctrl_cost,
            "reward_approach_ball": approach_ball_reward,
            "reward_kick": kick_reward,
            "reward_goal": goal_reward,
            "robot_position": robot_pos_after.copy(),
            "ball_position": ball_pos_after.copy(),
            "distance_to_ball": dist_to_ball_after,
            "ball_to_goal_distance": ball_to_goal_after,
            "is_healthy": self.is_healthy,
            "goal_scored": goal_reward > 0,
        }
        
        truncated = False
        
        return observation, reward, terminated, truncated, info
    
    def reset_model(self):
        """é‡ç½®ç’°å¢ƒ"""
        noise_low = -self._reset_noise_scale
        noise_high = self._reset_noise_scale
        
        # è¤‡è£½åˆå§‹ç‹€æ…‹ï¼ˆé€™åŒ…å« XML ä¸­å®šç¾©çš„åˆå§‹ä½ç½®ï¼‰
        qpos = self.init_qpos.copy()
        qvel = self.init_qvel.copy()
        
        # ========== é‡è¦ï¼šä¿ç•™ humanoid çš„åˆå§‹é«˜åº¦ ==========
        # init_qpos å·²ç¶“åŒ…å« XML ä¸­å®šç¾©çš„æ­£ç¢ºä½ç½® (0, 0, 1.4)
        # æˆ‘å€‘åªå°é—œç¯€è§’åº¦åŠ å™ªéŸ³ï¼Œä¸å‹•ä½ç½®å’Œå§¿æ…‹
        
        # humanoid çš„ qpos çµæ§‹ï¼š
        # [0:3] = x, y, z ä½ç½®
        # [3:7] = å››å…ƒæ•¸ (w, x, y, z) å§¿æ…‹
        # [7:] = å„é—œç¯€è§’åº¦
        
        # åªå°é—œç¯€è§’åº¦åŠ å°å™ªéŸ³ï¼ˆå¾ç´¢å¼• 7 é–‹å§‹åˆ°çƒä¹‹å‰ï¼‰
        joint_start = 7
        joint_end = self._humanoid_qpos_end
        num_joints = joint_end - joint_start
        
        if num_joints > 0:
            qpos[joint_start:joint_end] += self.np_random.uniform(
                low=noise_low, high=noise_high, size=num_joints
            )
        
        # å° humanoid çš„é€Ÿåº¦åŠ å°å™ªéŸ³
        qvel[:self._humanoid_qvel_end] += self.np_random.uniform(
            low=noise_low, high=noise_high, size=self._humanoid_qvel_end
        )
        
        # ========== é‡ç½®çƒçš„ä½ç½® ==========
        # çƒæ”¾åœ¨æ©Ÿå™¨äººå‰æ–¹
        ball_x = self._ball_initial_distance + self.np_random.uniform(-0.3, 0.3)
        ball_y = self.np_random.uniform(-0.3, 0.3)
        ball_z = 0.15  # ç¨å¾®é«˜ä¸€é»ï¼Œè®“çƒè‡ªç„¶è½åˆ°åœ°é¢
        
        # è¨­å®šçƒçš„ qpos (ä½ç½® xyz + å››å…ƒæ•¸ wxyz)
        qpos[self._ball_qpos_adr:self._ball_qpos_adr + 3] = [ball_x, ball_y, ball_z]
        qpos[self._ball_qpos_adr + 3:self._ball_qpos_adr + 7] = [1, 0, 0, 0]
        
        # çƒçš„é€Ÿåº¦è¨­ç‚º 0
        qvel[self._ball_qvel_adr:self._ball_qvel_adr + 6] = 0
        
        self.set_state(qpos, qvel)
        
        # ========== é—œéµä¿®æ­£ï¼šè®“æ©Ÿå™¨äººè‡ªç„¶ä¸‹è½ä¸¦ç©©å®šæ¥åœ° ==========
        # åŸ·è¡Œå¹¾æ­¥é›¶å‹•ä½œï¼ˆä¸è¼¸å…¥ä»»ä½•åŠ›ï¼‰ï¼Œè®“é‡åŠ›ä½œç”¨
        # é€™ç¢ºä¿æ©Ÿå™¨äººè…³éƒ¨æ¥è§¸åœ°é¢ï¼Œè€Œä¸æ˜¯ä¾è³´æ¨¡å‹å­¸æœƒå°æŠ—é‡åŠ›
        zero_action = np.zeros(self.action_space.shape[0])
        for _ in range(10):
            self.do_simulation(zero_action, self.frame_skip)
        
        return self._get_obs()
    
    def reset(self, *, seed=None, options=None):
        """é‡ç½®ç’°å¢ƒä¸¦å›å‚³è§€å¯Ÿå’Œè³‡è¨Š"""
        obs, info = super().reset(seed=seed, options=options)
        
        # åŠ å…¥é¡å¤–è³‡è¨Š
        ball_pos = self._get_ball_position()
        robot_pos = self._get_robot_position()
        
        info.update({
            "ball_position": ball_pos.copy(),
            "robot_position": robot_pos.copy(),
            "distance_to_ball": np.linalg.norm(robot_pos[:2] - ball_pos[:2]),
            "ball_to_goal_distance": np.linalg.norm(self._goal_position[:2] - ball_pos[:2]),
        })
        
        return obs, info


def make_soccer_env(render_mode=None, **kwargs):
    """å»ºç«‹è¶³çƒç’°å¢ƒçš„è¼”åŠ©å‡½æ•¸"""
    return HumanoidSoccerEnv(render_mode=render_mode, **kwargs)


# ==================== æ¸¬è©¦ç¨‹å¼ç¢¼ ====================
if __name__ == "__main__":
    import time
    
    print("=" * 60)
    print("æ¸¬è©¦ HumanoidSoccerEnv")
    print("=" * 60)
    
    # å»ºç«‹ç’°å¢ƒ
    env = HumanoidSoccerEnv(render_mode="human")
    
    print(f"\nğŸ“Š ç’°å¢ƒè³‡è¨Š:")
    print(f"   è§€å¯Ÿç©ºé–“: {env.observation_space.shape}")
    print(f"   å‹•ä½œç©ºé–“: {env.action_space.shape}")
    
    # é‡ç½®ç’°å¢ƒ
    obs, info = env.reset()
    print(f"\nğŸ“ åˆå§‹ç‹€æ…‹:")
    print(f"   è§€å¯Ÿç¶­åº¦: {obs.shape}")
    print(f"   æ©Ÿå™¨äººä½ç½®: {info['robot_position']}")
    print(f"   çƒä½ç½®: {info['ball_position']}")
    print(f"   åˆ°çƒè·é›¢: {info['distance_to_ball']:.3f}")
    print(f"   çƒåˆ°çƒé–€è·é›¢: {info['ball_to_goal_distance']:.3f}")
    
    # è·‘å¹¾æ­¥æ¸¬è©¦
    print(f"\nğŸ® é–‹å§‹æ¸¬è©¦ï¼ˆè§€å¯Ÿè¦–çª—ä¸­çš„æ©Ÿå™¨äººï¼‰...")
    print(f"   æç¤ºï¼šæ©Ÿå™¨äººæœƒå…ˆå¾ç©ºä¸­è½ä¸‹ï¼Œç„¶å¾Œé–‹å§‹éš¨æ©Ÿå‹•ä½œ")
    print(f"   å› ç‚ºæ˜¯éš¨æ©Ÿå‹•ä½œï¼Œæ©Ÿå™¨äººæœƒå¾ˆå¿«å€’ä¸‹ï¼Œé€™æ˜¯æ­£å¸¸çš„ï¼\n")
    
    episode_reward = 0
    episode_count = 0
    
    for i in range(2000):
        # éš¨æ©Ÿå‹•ä½œ
        action = env.action_space.sample()
        obs, reward, terminated, truncated, info = env.step(action)
        episode_reward += reward
        
        # å¼·åˆ¶æ¸²æŸ“ï¼ˆç¢ºä¿è¦–çª—æ›´æ–°ï¼‰
        env.render()
        
        # ç¨å¾®æ¸›æ…¢é€Ÿåº¦ï¼Œè®“äººçœ¼èƒ½çœ‹æ¸…æ¥š
        time.sleep(0.01)
        
        if i % 200 == 0:
            print(f"   Step {i:4d}: reward={reward:7.3f}, "
                  f"dist_to_ball={info['distance_to_ball']:.3f}, "
                  f"robot_z={info['robot_position'][2]:.3f}, "
                  f"ball_z={info['ball_position'][2]:.3f}")
        
        if terminated:
            episode_count += 1
            print(f"\nâš ï¸  Episode {episode_count} çµæŸæ–¼ step {i}")
            if info.get('goal_scored'):
                print("   ğŸ‰ é€²çƒäº†ï¼")
            else:
                print("   ğŸ’€ æ©Ÿå™¨äººå€’ä¸‹äº† (robot_z={:.3f})".format(info['robot_position'][2]))
            print(f"   ç´¯è¨ˆçå‹µ: {episode_reward:.2f}")
            episode_reward = 0
            obs, info = env.reset()
            
            if episode_count >= 10:
                print("\nå·²å®Œæˆ 10 å€‹ episodeï¼ŒçµæŸæ¸¬è©¦")
                break
    
    env.close()
    print("\nâœ… æ¸¬è©¦å®Œæˆï¼")